{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "import pymupdf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.nature.com/articles/s41566-019-0398-2</td>\n",
       "      <td>1</td>\n",
       "      <td>Surface passivation of perovskite film for eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nature.com/articles/s41560-020-007...</td>\n",
       "      <td>1</td>\n",
       "      <td>Intact 2D/3D halide junction perovskite solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nature.com/articles/s41467-021-236...</td>\n",
       "      <td>1</td>\n",
       "      <td>Multication perovskite 2D/3D interfaces form v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://doi.org/10.1038%2Fs41586-022-04604-5</td>\n",
       "      <td>1</td>\n",
       "      <td>Stability-limiting heterointerfaces of perovsk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://doi.org/10.1038%2Fs41467-022-30426-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Imaging and quantifying non-radiative losses a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  label  \\\n",
       "0  https://www.nature.com/articles/s41566-019-0398-2      1   \n",
       "1  https://www.nature.com/articles/s41560-020-007...      1   \n",
       "2  https://www.nature.com/articles/s41467-021-236...      1   \n",
       "3       https://doi.org/10.1038%2Fs41586-022-04604-5      1   \n",
       "4       https://doi.org/10.1038%2Fs41467-022-30426-0      1   \n",
       "\n",
       "                                                text  \n",
       "0  Surface passivation of perovskite film for eff...  \n",
       "1  Intact 2D/3D halide junction perovskite solar ...  \n",
       "2  Multication perovskite 2D/3D interfaces form v...  \n",
       "3  Stability-limiting heterointerfaces of perovsk...  \n",
       "4  Imaging and quantifying non-radiative losses a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('../data/merged_label.csv')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making PDFs of each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_url(url):\n",
    "    \"\"\"Gets the base url from a given url (i.e. https://www.nature.com)\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    return f\"{parsed.scheme}://{parsed.netloc}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    \"\"\"Gets the content of a given url with user headers\"\"\"\n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:106.0) Gecko/20100101 Firefox/106.0')\n",
    "    req.add_header('Accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8')\n",
    "    req.add_header('Accept-Language', 'en-US,en;q=0.5')\n",
    "\n",
    "    r = urllib.request.urlopen(req)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_url(url):\n",
    "    \"\"\"Gets the url after redirection for a given url\"\"\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}\n",
    "    r = requests.get(url, headers=headers, allow_redirects=True)\n",
    "    parsed_uri = urlparse(r.url)\n",
    "    print(r.url)\n",
    "    return f'{parsed_uri.scheme}://{parsed_uri.netloc}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_eof(pdf_content):\n",
    "    \"\"\"Some PDFs have an early EOF marker, which confuses PyMuPDF, \n",
    "    this moves it to the end of the file. Sometimes there is no EOF marker, \n",
    "    so we add one.\"\"\"\n",
    "    # find the line position of the EOF\n",
    "    EOF_MARKER = b'%%EOF'\n",
    "    if EOF_MARKER in pdf_content:\n",
    "        # we can remove the early %%EOF and put it at the end of the file\n",
    "        pdf_content = pdf_content.replace(EOF_MARKER, b'')\n",
    "        pdf_content = pdf_content + EOF_MARKER\n",
    "    else:\n",
    "        # Some files really don't have an EOF marker\n",
    "        # printed b'\\n%%EO%E'\n",
    "        pdf_content = pdf_content[:-6] + EOF_MARKER\n",
    "    return pdf_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_pdfs(url, paper_index):\n",
    "    \"\"\"Finds and downloads all pdfs for a given paper. \n",
    "    Uses PyMuPDF to download and merge all pdfs on the page into one.\"\"\"\n",
    "    page = get_page(url)\n",
    "    url = get_actual_url(url)\n",
    "    print(url)\n",
    "    soup = BeautifulSoup(page.read().decode(\"utf-8\"), 'html.parser')\n",
    "    \n",
    "    # Find all unique PDF links on the page\n",
    "    pdf_links = [link.get('href') for link in soup.find_all('a', href=True) \\\n",
    "                 if link.get('href') and 'pdf' in urlparse(link.get('href')).path.lower()]\n",
    "    pdf_links = list(set(pdf_links))\n",
    "    \n",
    "    # Initialize a new PDF document to store the merged pages\n",
    "    merged_pdf = pymupdf.open()\n",
    "    i = 0\n",
    "    print(pdf_links)\n",
    "    for pdf_link in pdf_links:\n",
    "        # Ensure each link is a full URL\n",
    "        pdf_url = pdf_link if pdf_link.startswith('http') else get_base_url(url) + pdf_link\n",
    "        print(pdf_url)\n",
    "        try:\n",
    "            res = requests.get(pdf_url, allow_redirects=True)\n",
    "            print(f\"Processing PDF URL: {res.url}\")\n",
    "        except:\n",
    "            print(f\"Skipping invalid PDF at {pdf_url}\")\n",
    "            continue\n",
    "        \n",
    "        # Load PDF content into a PyMuPDF document\n",
    "        try:\n",
    "            pdf_stream = BytesIO(res.content)\n",
    "            pdf_document = pymupdf.open(stream=pdf_stream, filetype=\"pdf\")\n",
    "            \n",
    "            # Append each page to the merged PDF\n",
    "            for page_num in range(pdf_document.page_count):\n",
    "                merged_pdf.insert_pdf(pdf_document, from_page=page_num, to_page=page_num)\n",
    "                \n",
    "            pdf_document.close()\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping invalid PDF at {pdf_url}: {e}\")\n",
    "    \n",
    "    # Save the merged PDF to disk\n",
    "    if (merged_pdf.page_count > 0):\n",
    "        merged_pdf.save(f'../data/pdfs/{paper_index}.pdf')\n",
    "        merged_pdf.close()\n",
    "        print(f\"Merged PDF saved as '../data/pdfs/{paper_index}.pdf'\")\n",
    "    else:\n",
    "        print(f\"No PDF links found for index {paper_index}.\")\n",
    "        #TODO : use selenium to download the pdf by printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating pdfs for each row in the merged dataframe\n",
    "for index, row in merged_df.iterrows():\n",
    "    print(row['link'])\n",
    "    download_all_pdfs(row['link'], index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "https://pubs.rsc.org/en/content/articlehtml/2019/ta/c9ta01070j\n",
      "39\n",
      "https://pubs.rsc.org/en/content/articlehtml/2019/ee/c9ee00453j\n",
      "71\n",
      "https://doi.org/10.48550/arXiv.2102.10399\n",
      "74\n",
      "https://doi.org/10.1146/annurev-food-022814-015651\n",
      "76\n",
      "https://doi.org/10.1039/C9CS00711C\n",
      "82\n",
      "https://doi.org/10.1039/TF937330008B\n",
      "90\n",
      "https://doi.org/10.1039%2FC7TA00434F\n",
      "97\n",
      "https://doi.org/10.1017/CBO9780511608810\n",
      "100\n",
      "https://doi.org/10.1146/annurev.bb.12.060183.001035\n",
      "105\n",
      "https://doi.org/10.1146/annurev.physchem.51.1.209\n",
      "120\n",
      "https://doi.org/10.1039/D1SM01707A\n",
      "125\n",
      "https://doi.org/10.1039%2FC4TA05033A\n",
      "128\n",
      "https://doi.org/10.1146/annurev.ms.12.080182.000535\n",
      "129\n",
      "https://doi.org/10.1039/DC9786500007\n"
     ]
    }
   ],
   "source": [
    "existing_files = {os.path.splitext(file)[0] for file in os.listdir('../data/pdfs')}\n",
    "for index, row in merged_df.iterrows():\n",
    "    index_str = str(index)\n",
    "    if index_str not in existing_files:\n",
    "        #showing which pdf prints were not successful (done manually for now, will be done with Selenium later)\n",
    "        print(index)\n",
    "        print(row['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PDFs to XML using GROBID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grobid_url = \"http://localhost:8070/api/processFulltextDocument\"\n",
    "xml_names = os.listdir(\"../data/xmls\")\n",
    "\n",
    "for pdf_file in os.listdir(\"../data/pdfs\"):\n",
    "    #only looks at pdf files\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(\"../data/pdfs\", pdf_file)\n",
    "        #doe not convert already converted files\n",
    "        if pdf_path.replace('.pdf', '.xml') in xml_names:\n",
    "            continue\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            #GROBID must be running on port 8070 for this to work\n",
    "            response = requests.post(\n",
    "                grobid_url,\n",
    "                files={'input': file},\n",
    "                headers={'Accept': 'application/xml'}\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                xml_file_path = os.path.join('../data/xmls', pdf_file.replace('.pdf', '.xml'))\n",
    "                with open(xml_file_path, 'w', encoding='utf-8') as xml_file:\n",
    "                    xml_file.write(response.text)\n",
    "                print(f\"Converted {pdf_file} to XML.\")\n",
    "            else:\n",
    "                print(f\"Failed to convert {pdf_file}. Status code: {response.status_code}\")\n",
    "                print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
