{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncoleban/DSC180_B11/mykernel/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from litellm import completion\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"llama-3.2-3b-it-Perovskite-PaperExtractor\"\n",
    "# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, ).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 60000\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.1,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"\n",
    "You are a helpful scientific assistant. Your task is to extract relevant scientific data from the provided text about perovskite solar cells and passivating molecules. If the data is not available in the text, return null for the respective fields. Output the information in JSON format with the following fields:\n",
    "- `control_pce`: Power conversion efficiency for control perovskite (numeric).\n",
    "- `control_voc`: Open-circuit voltage for control perovskite (numeric).\n",
    "- `treated_pce`: Best Power conversion efficiency for treated perovskite (numeric).\n",
    "- `treated_voc`: Best Open-circuit voltage for treated perovskite (numeric).\n",
    "- `passivating_molecule`: Name of the champion passivating molecule tested.\n",
    "- `perovskite_composition`: Chemical formula of the perovskite (string).\n",
    "- `electron_transport_layer`: Material used as the electron transport layer (string).\n",
    "- `hole_transport_layer`: Material used as the hole transport layer (string).\n",
    "- Stability tests: Include any stability tests mentioned. Stability tests can be done in dark storage, light-soaking, thermal cycling, light cycling, and solar-thermal cycling. If none of these types are tested, do not include a JSON object for them.\n",
    "Make sure that all numeric variables are proper javascript numbers. If not, return them as a string.\n",
    "For each test, the value should follow this format:\n",
    "```json\n",
    "{\n",
    "  \"test_name\": null,\n",
    "  \"temperature\": null (numeric - only return the number in degrees celsius),\n",
    "  \"time\": null,\n",
    "  \"humidity\": null (string),\n",
    "  \"control_efficiency\": null,\n",
    "  \"treatment_efficiency\": null\n",
    "}\n",
    "\n",
    "The JSON structure must follow this exact format:\n",
    "{\n",
    "  \"control_pce\": null,\n",
    "  \"control_voc\": null,\n",
    "  \"treated_pce\": null,\n",
    "  \"treated_voc\": null,\n",
    "  \"passivating_molecule\": null,\n",
    "  \"perovskite_composition\": null,\n",
    "  \"electron_transport_layer\": null,\n",
    "  \"hole_transport_layer\": null,\n",
    "  \"stability_tests\": [\n",
    "    {\n",
    "      \"test_name\": null,\n",
    "      \"temperature\": null,\n",
    "      \"time\": null,\n",
    "      \"humidity\": null,\n",
    "      \"control_efficiency\": null,\n",
    "      \"treatment_efficiency\": null\n",
    "    },\n",
    "  ]\n",
    "}\n",
    "Be concise and accurate. Include only information explicitly present in the text.\n",
    "Don't return ranges for any values, as this will cause the JSON to not parse correctly. If a range is presented, return the range as a string. This is any value that has a \"-\" in it.\n",
    "Do not include the \"%\" sign for any value, this will cause the JSON to parse incorrectly. Either do not include it or return a string - specifically for PCE and effiicency variables.\n",
    "Do not include the degree symbol for any value, this will cause the JSON to parse incorrectly.\n",
    "**make sure no unparseable JSON is returned as values for any of these properties**\n",
    "Only return JSON. The text is below:\n",
    "\"\"\"\n",
    "SUFFIX = \"\"\"\\n\\n{sample}\\n\\n\"\"\"\n",
    "def create_prompt(system, user):\n",
    "    tokens = tokenizer.encode(user, max_length=25000, truncation=True)\n",
    "    truncated_user = tokenizer.decode(tokens)\n",
    "    return [\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": truncated_user}, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "txt_dir = \"../../data/txts\"\n",
    "for filename in os.listdir(txt_dir):\n",
    "    if filename.endswith(\".txt\") == False:\n",
    "        continue\n",
    "    filepath = os.path.join(txt_dir, filename)\n",
    "    paper_id = os.path.splitext(filename)[0]\n",
    "    print(paper_id)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        instruction = create_prompt(PREFIX, text)\n",
    "        json_string = pipe(instruction, max_new_tokens=1024)[0][\"generated_text\"][-1]['content']\n",
    "        json_match = re.search(r\"\\{.*\\}\", json_string, re.DOTALL)\n",
    "        if json_match:\n",
    "            raw_json = json_match.group(0).strip()\n",
    "        else:\n",
    "            print(\"No JSON found\")\n",
    "            continue\n",
    "        # clean_json_string = json_string.strip(\"```json\").strip(\"```\").strip()\n",
    "        try:\n",
    "            parsed_data = json.loads(raw_json)\n",
    "            contents[paper_id] = parsed_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error creating JSON\", e)\n",
    "            print(raw_json)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"../../data/finetuned_llama_output.json\"\n",
    "with open(json_path, \"w\") as file:\n",
    "    json.dump(contents, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
